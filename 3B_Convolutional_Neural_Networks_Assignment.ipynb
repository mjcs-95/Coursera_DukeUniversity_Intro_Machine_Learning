{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Assignment: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Duke Community Standard](http://integrity.duke.edu/standard.html): By typing your name below, you are certifying that you have adhered to the Duke Community Standard in completing this assignment.**\n",
    "\n",
    "Name: Manuel Jesús Corbacho Sánchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "Adapt the CNN example for MNIST digit classfication from Notebook 3A. \n",
    "Feel free to play around with the model architecture and see how the training time/performance changes, but to begin, try the following:\n",
    "\n",
    "Image ->  \n",
    "convolution (32 3x3 filters) -> nonlinearity (ReLU) ->  \n",
    "convolution (32 3x3 filters) -> nonlinearity (ReLU) -> (2x2 max pool) ->  \n",
    "convolution (64 3x3 filters) -> nonlinearity (ReLU) ->  \n",
    "convolution (64 3x3 filters) -> nonlinearity (ReLU) -> (2x2 max pool) -> flatten ->\n",
    "fully connected (256 hidden units) -> nonlinearity (ReLU) ->  \n",
    "fully connected (10 hidden units) -> softmax \n",
    "\n",
    "Note: The CNN model might take a while to train. Depending on your machine, you might expect this to take up to half an hour. If you see your validation performance start to plateau, you can kill the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609fc563b774468d94fbdd622cad4f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cf29ce001b4dad9f76e4e784e0a44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "    \n",
    "# Parameters of the learning\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "samples_per_batch = 100\n",
    "stride_size = 1\n",
    "\n",
    "class MNIST_CNN_assignment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d( 1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.set_fc1 = False\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.max_pool = nn.MaxPool2d(2,stride_size)\n",
    "        self.viewsize = 0\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))          # conv layer 1\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.conv2(x))          # conv layer 2\n",
    "        # print(x.shape)\n",
    "        x = self.max_pool(x)                    # pool         \n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.conv3(x))          # conv layer 3\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.conv4(x))          # conv layer 4         \n",
    "        # print(x.shape)\n",
    "        x = self.max_pool(x)                    # pool      \n",
    "        if not self.set_fc1:\n",
    "            self.viewsize = x.shape[2]*x.shape[3]*64\n",
    "            self.fc1 = nn.Linear(self.viewsize, 256)\n",
    "            self.set_fc1 = True\n",
    "            self.to(device)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x.view(-1, self.viewsize)))            # fc layer 1        \n",
    "        # print(x.shape)\n",
    "        x = self.fc2(x)                    # fc layer 2        \n",
    "        # print(x.shape)\n",
    "        return x   \n",
    "    '''\n",
    "    torch.Size([100, 32, 26, 26])\n",
    "    torch.Size([100, 32, 24, 24])\n",
    "    torch.Size([100, 32, 23, 23])\n",
    "    torch.Size([100, 64, 21, 21])\n",
    "    torch.Size([100, 64, 19, 19])\n",
    "    torch.Size([100, 64, 18, 18])\n",
    "    torch.Size([2025, 1024])\n",
    "    torch.Size([2025, 256])\n",
    "    torch.Size([2025, 10])\n",
    "    '''\n",
    "    \n",
    "# Load the data\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=samples_per_batch, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=samples_per_batch, shuffle=False)\n",
    "\n",
    "## Training\n",
    "# Instantiate model\n",
    "model = MNIST_CNN_assignment().to(device)\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for i in trange(epochs):\n",
    "    # Iterate through train set minibatchs \n",
    "    for images, labels in tqdm(train_loader):        \n",
    "        # Zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass        \n",
    "        x = images.to(device)\n",
    "        y = model(x)\n",
    "        loss = criterion(y, labels.to(device))\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "## Testing\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate through test set minibatchs \n",
    "    for images, labels in tqdm(test_loader):\n",
    "        # Forward pass\n",
    "        x = images.to(device)\n",
    "        y = model(x)        \n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions == labels.to(device)).float())\n",
    "print('Test accuracy: {}'.format(correct/total))\n",
    "# Make sure to print out your accuracy on the test set at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short answer\n",
    "\n",
    "1\\. How does the CNN compare in accuracy with yesterday's logistic regression and MLP models? How about training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`With the logistic regression, the accuracy was 90%, meanwhile the MLP's accuracy was in the range 92-95%, on the other hand, the CNN can get an accuracy of 98% `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many trainable parameters are there in the CNN you built for this assignment?\n",
    "\n",
    "*Note: The total of trainable parameters counts each element in a tensor. For example, a weight matrix that is 10x5 has 50 trainable parameters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5376234\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Our model has 5376234 trainable parameters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. When would you use a CNN versus a logistic regression model or an MLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Most of the time, the CNN will be used to work with images, where it performs better than the MLP or a logistic regression. CNN should also be able to handle more difficult problems than the ones that can be handled by MLP or Logistic Regression.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
